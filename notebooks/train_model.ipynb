{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o modelo e o tokenizador\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Supondo que seu dataset está em uma lista de strings\n",
    "data = pd.read_csv(\"../data/13k-recipes.csv\")  # substitua pelo caminho do seu arquivo\n",
    "data = data.dropna()\n",
    "data = data[\"Instructions\"].tolist()\n",
    "sentences = data[:5000]\n",
    "\n",
    "# Criar pares duplicados (positivos)\n",
    "class ContrastiveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sentences):\n",
    "        self.sentences = sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.sentences[idx]\n",
    "        inputs_a = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
    "        inputs_b = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", max_length=128, truncation=True)\n",
    "        return inputs_a, inputs_b\n",
    "\n",
    "train_dataset = ContrastiveDataset(sentences)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pat chicken dry with paper towels, season all over with 2 tsp. salt, and tie legs together with kitchen twine. Let sit at room temperature 1 hour.\\nMeanwhile, halve squash and scoop out seeds. Run a vegetable peeler along ridges of squash halves to remove skin. Cut each half into ½\"-thick wedges; arrange on a rimmed baking sheet.\\nCombine sage, rosemary, and 6 Tbsp. melted butter in a large bowl; pour half of mixture over squash on baking sheet. Sprinkle squash with allspice, red pepper flakes, and ½ tsp. salt and season with black pepper; toss to coat.\\nAdd bread, apples, oil, and ¼ tsp. salt to remaining herb butter in bowl; season with black pepper and toss to combine. Set aside.\\nPlace onion and vinegar in a small bowl; season with salt and toss to coat. Let sit, tossing occasionally, until ready to serve.\\nPlace a rack in middle and lower third of oven; preheat to 425°F. Mix miso and 3 Tbsp. room-temperature butter in a small bowl until smooth. Pat chicken dry with paper towels, then rub or brush all over with miso butter. Place chicken in a large cast-iron skillet and roast on middle rack until an instant-read thermometer inserted into the thickest part of breast registers 155°F, 50–60 minutes. (Temperature will climb to 165°F while chicken rests.) Let chicken rest in skillet at least 5 minutes, then transfer to a plate; reserve skillet.\\nMeanwhile, roast squash on lower rack until mostly tender, about 25 minutes. Remove from oven and scatter reserved bread mixture over, spreading into as even a layer as you can manage. Return to oven and roast until bread is golden brown and crisp and apples are tender, about 15 minutes. Remove from oven, drain pickled onions, and toss to combine. Transfer to a serving dish.\\nUsing your fingers, mash flour and butter in a small bowl to combine.\\nSet reserved skillet with chicken drippings over medium heat. You should have about ¼ cup, but a little over or under is all good. (If you have significantly more, drain off and set excess aside.) Add wine and cook, stirring often and scraping up any browned bits with a wooden spoon, until bits are loosened and wine is reduced by about half (you should be able to smell the wine), about 2 minutes. Add butter mixture; cook, stirring often, until a smooth paste forms, about 2 minutes. Add broth and any reserved drippings and cook, stirring constantly, until combined and thickened, 6–8 minutes. Remove from heat and stir in miso. Taste and season with salt and black pepper.\\nServe chicken with gravy and squash panzanella alongside.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(embeddings_a, embeddings_b, similarity_target=1.0):\n",
    "    cosine_sim = F.cosine_similarity(embeddings_a, embeddings_b)\n",
    "    loss = F.mse_loss(cosine_sim, torch.ones_like(cosine_sim) * similarity_target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talinho\\OneDrive - Insper - Institudo de Ensino e Pesquisa\\Área de Trabalho\\Insper\\NLP\\cookembeddings\\.venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/3:   0%|          | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Average Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    # Barra de progresso para cada epoch\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        start_time = time.time()\n",
    "        inputs_a, inputs_b = batch\n",
    "        inputs_a = {k: v.squeeze().to(device) for k, v in inputs_a.items()}\n",
    "        inputs_b = {k: v.squeeze().to(device) for k, v in inputs_b.items()}\n",
    "\n",
    "        # Obter embeddings\n",
    "        outputs_a = model(**inputs_a).last_hidden_state.mean(dim=1)\n",
    "        outputs_b = model(**inputs_b).last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # Calcular a perda\n",
    "        loss = contrastive_loss(outputs_a, outputs_b)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Backpropagation e atualização dos pesos\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Atualizar a barra de progresso com a perda média e o tempo por batch\n",
    "        progress_bar.set_postfix({\n",
    "            \"batch_loss\": loss.item(),\n",
    "            \"avg_loss\": epoch_loss / (batch_idx + 1),\n",
    "            \"batch_time\": f\"{time.time() - start_time:.2f}s\"\n",
    "        })\n",
    "\n",
    "    # Print da perda média por epoch após cada época\n",
    "    print(f\"Epoch {epoch + 1} completed. Average Loss: {epoch_loss / len(train_dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/finetuned-tokenizer\\\\tokenizer_config.json',\n",
       " '../models/finetuned-tokenizer\\\\special_tokens_map.json',\n",
       " '../models/finetuned-tokenizer\\\\vocab.txt',\n",
       " '../models/finetuned-tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/finetuned-bert\")\n",
    "tokenizer.save_pretrained(\"../models/finetuned-tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
